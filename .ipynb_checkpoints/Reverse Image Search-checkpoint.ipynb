{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12236,
     "status": "ok",
     "timestamp": 1577994678600,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "Xe6n6TpTQR6N",
    "outputId": "b376143f-bd98-4814-90ac-c255bf7d3583"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import pandas as pd\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13490,
     "status": "ok",
     "timestamp": 1577994679868,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "td7_r3OeQq5a",
    "outputId": "2e644ce5-ea0a-4ed0-cc96-fef566f64aad"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "results_csv_path = '/content/drive/Shared drives/Deep Six Design/Deep Six Design/Projects/Neural Art Process/alexgrey_images/results.csv'\n",
    "results_txt_path = '/content/drive/Shared drives/Deep Six Design/Deep Six Design/Projects/Neural Art Process/alexgrey_images/results.txt'\n",
    "images_path = '/content/drive/Shared drives/Deep Six Design/Deep Six Design/Projects/Neural Art Process/alexgrey_images/alexgrey_images/'\n",
    "test_image_path = '/content/drive/Shared drives/Deep Six Design/Deep Six Design/Projects/Neural Art Process/alexgrey_images/alexgrey_images/00000000.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtUxKcSMQR6S"
   },
   "outputs": [],
   "source": [
    "# read image descriptions\n",
    "image_descriptions = pd.read_csv(results_csv_path, sep='\\|\\s', engine='python')\n",
    "selected_columns = ['image_name', 'comment']\n",
    "image_descriptions = image_descriptions[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vq_oJtiaSx2"
   },
   "outputs": [],
   "source": [
    "# create a language model quickly with fasttext\n",
    "fasttext_model = ft.train_unsupervised(model='skipgram', input=results_txt_path)\n",
    "# save model\n",
    "fasttext_model.save_model(\"ftxt_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20413,
     "status": "ok",
     "timestamp": 1577994686815,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "tWWqm_xpafDB",
    "outputId": "ad6c5d5f-1b50-45c3-bad8-992136c8dba9"
   },
   "outputs": [],
   "source": [
    "# load saved model\n",
    "fasttext_model = ft.load_model(\"ftxt_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23141,
     "status": "ok",
     "timestamp": 1577994689552,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "CHAcnyETarSs",
    "outputId": "770ea9f9-5661-40a8-8337-03ec9b77fc06"
   },
   "outputs": [],
   "source": [
    "# convert string to embeddings\n",
    "fasttext_model.get_sentence_vector('alex grey is painting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23133,
     "status": "ok",
     "timestamp": 1577994689553,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "VMAlmg4uQR6h",
    "outputId": "b74ee4eb-b1d3-4c7e-9aa8-ff8766397584"
   },
   "outputs": [],
   "source": [
    "def concater(x):\n",
    "    try:\n",
    "        return ' '.join(x)\n",
    "    except Exception as e:\n",
    "        return ''\n",
    "\n",
    "# concatenate strings for same images\n",
    "image_descriptions['comment'] = image_descriptions.groupby(['image_name'])['comment'].transform(concater)\n",
    "image_descriptions = image_descriptions[['image_name','comment']].drop_duplicates()\n",
    "image_descriptions.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lM9LOvD6QR6n"
   },
   "outputs": [],
   "source": [
    "# load mobilenet featurevector model as a Keras layer\n",
    "module = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
    "        output_shape=[1280],\n",
    "        trainable=False)\n",
    "])\n",
    "\n",
    "# build the model\n",
    "module.build([None, 224, 224, 3])\n",
    "\n",
    "# This model will only accept images of size 224 x 224\n",
    "# So, we need to make sure throughout the code, that we supply correcty resized images\n",
    "im_height, im_width = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOgHwKqTQR6p"
   },
   "outputs": [],
   "source": [
    "# Here is the helper function to load and resize image\n",
    "def load_rsize_image(filename, w, h):\n",
    "    # open the image file\n",
    "    im = Image.open(filename)\n",
    "    # resize the image\n",
    "    im = im.resize(size=(w, h))\n",
    "    return np.asarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29499,
     "status": "ok",
     "timestamp": 1577994695941,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "bf3BUIOkQR6r",
    "outputId": "0b6b7100-ca55-421a-84fd-3d8d7314d863"
   },
   "outputs": [],
   "source": [
    "# Let's test loading an image\n",
    "image_array = load_rsize_image(test_image_path, im_width, im_height)\n",
    "plt.imshow(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zKai5_YQR6u"
   },
   "outputs": [],
   "source": [
    "# helper function to retrieve fasttext word embeddings\n",
    "def get_ftxt_embeddings(text):\n",
    "    return fasttext_model.get_sentence_vector(text)\n",
    "\n",
    "# helper function to encode images with mobilenet\n",
    "def get_image_encodings(batch, module):\n",
    "    message_embeddings = module.predict(batch)\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__Y8WxrqQR61"
   },
   "outputs": [],
   "source": [
    "# helper function to embed images and comments in a dataframe and return numpy metrices\n",
    "# this function will iterate through a dataframe, which contains image file names in one column and \n",
    "# comments in another column and will generate seperate matrices for images and comments.\n",
    "# row order of these matrices matters because same row index in both matrices represent related image and comments.\n",
    "def embed_all(df, w, h):\n",
    "    img_arr = []\n",
    "    txt_arr = []\n",
    "    # for each row, embed data\n",
    "    for index, row in df.iterrows():\n",
    "        # img_arr will contain all the image file data (will be passed to mobilenet later)\n",
    "        img_arr.append(load_rsize_image(images_path + row['image_name'], w, h))\n",
    "        # txt_arr will contain all Fasttext sentance embedding for each comment \n",
    "        txt_arr.append(get_ftxt_embeddings(row['comment']))\n",
    "    return img_arr, txt_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-cJXswBQR66"
   },
   "outputs": [],
   "source": [
    "img_emb, txt_emb = embed_all(image_descriptions, im_width, im_height)\n",
    "# reset fasttext model\n",
    "fasttext_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29920,
     "status": "ok",
     "timestamp": 1577994696399,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "zWhHd6x5QR6_",
    "outputId": "caa04621-6aa5-4f14-8ede-8e5c9e5c7758"
   },
   "outputs": [],
   "source": [
    "# verify that image is image loded correctly\n",
    "plt.imshow(img_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43326,
     "status": "ok",
     "timestamp": 1577994709816,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "oPw11IkEQR7E",
    "outputId": "fc8b5c9d-cf1e-499a-fa33-86f8ddd246a4"
   },
   "outputs": [],
   "source": [
    "# test image encodings generation\n",
    "get_image_encodings(np.true_divide(np.array(img_emb[0:100]), 255), module).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46153,
     "status": "ok",
     "timestamp": 1577994712652,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "wGLGn_dGQR7O",
    "outputId": "8dd9e92f-313b-4660-aa8e-3bb3a5e8906c"
   },
   "outputs": [],
   "source": [
    "# install AquilaDb python client\n",
    "\n",
    "! pip install aquiladb\n",
    "\n",
    "# import AquilaDB client\n",
    "from aquiladb import AquilaClient as acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaROHqYhQR7S"
   },
   "outputs": [],
   "source": [
    "# create DB instance.\n",
    "# Please provide the IP address of the machine that have AquilaDB installed in.\n",
    "db = acl('http://35.232.80.141/', 50051)\n",
    "\n",
    "# let's get our hands dirty for a moment..\n",
    "# convert a sample dirty Document\n",
    "sample = db.convertDocument([0.1,0.2,0.3,0.4], {\"alex\": \"grey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46142,
     "status": "ok",
     "timestamp": 1577994712656,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "4xo0VwPjQR7U",
    "outputId": "d058cab8-8f5d-46a8-83b8-b54821bb8a1b"
   },
   "outputs": [],
   "source": [
    "# and print it\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46783,
     "status": "error",
     "timestamp": 1577994713305,
     "user": {
      "displayName": "Peter Arnold",
      "photoUrl": "",
      "userId": "11243154511782282918"
     },
     "user_tz": 300
    },
    "id": "yAa1ay_2QR7Z",
    "outputId": "0dd82eb6-a3b1-4660-d988-e1e9712f3a16"
   },
   "outputs": [],
   "source": [
    "# batch length - to be sent to mobilenet for encoding\n",
    "blen = 3\n",
    "# which index to start encoding - ofcause its 0\n",
    "vstart = 0\n",
    "# How much images/text we need to encode\n",
    "vend = 3\n",
    "\n",
    "# convert text embeddings to numpy array\n",
    "txt_emb = np.array(txt_emb)\n",
    "\n",
    "# iterate over each batch of image/text data/embedding\n",
    "for ndx in range(vstart, vend, blen):\n",
    "    # encode each batch of images\n",
    "    image_encoding = get_image_encodings(np.true_divide(np.array(img_emb[ndx:ndx+blen]), 255), module)\n",
    "    \n",
    "    # pad image and text vectors - this is discussed in section `filter based indexing`\n",
    "    # select subset of data we're interested for text embeddings\n",
    "    text_embedding = txt_emb[ndx:ndx+blen]\n",
    "    # pad text encodings with trailing zeros\n",
    "    text_embedding = np.pad(text_embedding, ((0, 0), (0, 1280)), 'constant')\n",
    "    # pad image encodings with preceding zeros\n",
    "    image_encoding = np.pad(image_encoding, ((0, 0), (100, 0)), 'constant')\n",
    "    \n",
    "    # finally, create and send each document\n",
    "    for i in range(blen):\n",
    "        # create document - text\n",
    "        doc_txt = db.convertDocument(text_embedding[i], {\"image_name\": image_descriptions.iloc[ndx+i][0]})\n",
    "        # create document - image\n",
    "        doc_img = db.convertDocument(image_encoding[i], {\"image_name\": image_descriptions.iloc[ndx+i][0]})\n",
    "        \n",
    "        # send documents - text\n",
    "        db.addDocuments([doc_txt])\n",
    "        # send documents - image\n",
    "        db.addDocuments([doc_img])\n",
    "    \n",
    "    # Wooh! done with nth batch   \n",
    "    print('Done: ', ndx, ndx+blen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcBTsj8uQR7d"
   },
   "source": [
    "#### search images by text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2OjDMTAQR7e"
   },
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# search by text\n",
    "def search_by_text(text_in):\n",
    "    # load saved model\n",
    "    fasttext_model = ft.load_model(\"ftxt_model.bin\")\n",
    "    # generate embeddings\n",
    "    text_embedding_ = fasttext_model.get_sentence_vector(text_in)\n",
    "    # pad text embedding\n",
    "    text_embedding_ = np.pad([text_embedding_], ((0, 0), (0, 1280)), 'constant')\n",
    "\n",
    "    # convert query matrix\n",
    "    q_matrix = db.convertMatrix(np.asarray(text_embedding_[0]))\n",
    "    # do k-NN search\n",
    "    k = 10\n",
    "    result = db.getNearest(q_matrix, k)\n",
    "    return json.loads(result.documents)\n",
    "\n",
    "# render images\n",
    "def render_images(doclist):\n",
    "    for doc in doclist:\n",
    "        filename = doc[\"doc\"][\"image_name\"]\n",
    "        im = Image.open(images_path + filename)\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmDkaQaAQR7g"
   },
   "source": [
    "#### text to image search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRrj4j3AQR7g"
   },
   "outputs": [],
   "source": [
    "render_images(search_by_text('grey'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEu7oOngQR7o"
   },
   "source": [
    "#### search images by image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmSQNnzRQR7o"
   },
   "outputs": [],
   "source": [
    "# search by image\n",
    "def search_by_image(image_in, w, h, module):\n",
    "    # load image\n",
    "    q_image = load_rsize_image(images_path + image_in, w, h)\n",
    "    q_image = np.array([np.asarray(q_image)])\n",
    "    # generate encodings\n",
    "    image_encoding_ = get_image_encodings(np.true_divide(q_image, 255), module)\n",
    "    # pad image encodings\n",
    "    image_encoding_ = np.pad(image_encoding_, ((0, 0), (100, 0)), 'constant')\n",
    "\n",
    "    # convert query matrix\n",
    "    q_matrix = db.convertMatrix(np.asarray(image_encoding_[0]))\n",
    "    # do k-NN search\n",
    "    k = 10\n",
    "    result = db.getNearest(q_matrix, k)\n",
    "    return json.loads(result.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fp1qrYfhQR7q"
   },
   "source": [
    "#### image to image search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDqKcsNHQR7q"
   },
   "outputs": [],
   "source": [
    "q_im_file = test_image_path\n",
    "\n",
    "# show query image\n",
    "render_images([{\"doc\":{\"image_name\": q_im_file}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "284wX60uQR7s"
   },
   "outputs": [],
   "source": [
    "# do search\n",
    "render_images(search_by_image(q_im_file, im_width, im_height, module))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reverse Image Search.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
